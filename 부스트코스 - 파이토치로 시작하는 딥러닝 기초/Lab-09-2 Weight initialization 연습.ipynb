{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good Initialization in Weight is much more important\n",
    "\n",
    "- Not all 0's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2006 RBM\n",
    "- Restricted : no connections within a layer\n",
    "- Pre-training\n",
    "- Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xavier2010 / He initialization 2015\n",
    "- Xaiver Normal Initialization\n",
    "- Xaiver Uniform Initialization\n",
    "- He Normal Initialization\n",
    "- He Uniform Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "training_epochs = 20\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dsets.MNIST(root='MNIST_data', train=True, transform=transforms.ToTensor())\n",
    "mnist_test = dsets.MNIST(root='MNIST_data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = torch.nn.Linear(784, 256, bias=True)\n",
    "linear2 = torch.nn.Linear(256, 256, bias=True)\n",
    "linear3 = torch.nn.Linear(256, 10, bias=True)\n",
    "relu = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3371,  1.5778, -0.9435,  ..., -1.3917, -0.9079,  1.6330],\n",
       "        [ 0.0306,  0.3587, -0.6631,  ...,  0.9687, -0.2138,  1.2170],\n",
       "        [-1.7550, -0.1530,  0.2656,  ...,  1.6182,  0.3594,  1.4337],\n",
       "        ...,\n",
       "        [ 0.3382, -0.9864, -0.7690,  ...,  1.0798,  0.8634,  0.4950],\n",
       "        [ 0.2922, -0.1261, -1.1612,  ..., -0.5381, -0.3303, -0.9882],\n",
       "        [ 1.8342,  1.8050,  1.0897,  ...,  0.5521,  0.2920, -0.6831]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.normal_(linear1.weight)\n",
    "torch.nn.init.normal_(linear2.weight)\n",
    "torch.nn.init.normal_(linear3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3).to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 153.991210938\n",
      "Epoch: 0002 cost = 35.972740173\n",
      "Epoch: 0003 cost = 21.992288589\n",
      "Epoch: 0004 cost = 15.176042557\n",
      "Epoch: 0005 cost = 10.973302841\n",
      "Epoch: 0006 cost = 8.108571053\n",
      "Epoch: 0007 cost = 6.156758785\n",
      "Epoch: 0008 cost = 4.559571743\n",
      "Epoch: 0009 cost = 3.521098137\n",
      "Epoch: 0010 cost = 2.690568447\n",
      "Epoch: 0011 cost = 1.960561633\n",
      "Epoch: 0012 cost = 1.510765195\n",
      "Epoch: 0013 cost = 1.135576963\n",
      "Epoch: 0014 cost = 0.928186357\n",
      "Epoch: 0015 cost = 0.802532434\n",
      "Epoch: 0016 cost = 0.552375376\n",
      "Epoch: 0017 cost = 0.552641392\n",
      "Epoch: 0018 cost = 0.463200450\n",
      "Epoch: 0019 cost = 0.393307000\n",
      "Epoch: 0020 cost = 0.349274218\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    for X,Y in data_loader:\n",
    "        X = X.view(-1, 28*28).to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost/total_batch\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다층 Layer & Xavier_uniform weight initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0812, -0.0807, -0.0679,  ..., -0.0906, -0.0587,  0.0927],\n",
       "        [-0.0613,  0.0023,  0.0298,  ..., -0.0426,  0.0027, -0.0952],\n",
       "        [-0.0398,  0.0915, -0.0893,  ...,  0.0949,  0.1035,  0.0818],\n",
       "        ...,\n",
       "        [-0.0556, -0.0426, -0.0623,  ...,  0.0671, -0.0772, -0.0652],\n",
       "        [-0.0812, -0.1014,  0.0155,  ..., -0.0153, -0.0307, -0.0996],\n",
       "        [-0.0295, -0.1072,  0.1052,  ..., -0.0547,  0.0244, -0.0234]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "linear1 = torch.nn.Linear(784, 512, bias=True)\n",
    "linear2 = torch.nn.Linear(512, 512, bias=True)\n",
    "linear3 = torch.nn.Linear(512, 512, bias=True)\n",
    "linear4 = torch.nn.Linear(512, 512, bias=True)\n",
    "linear5 = torch.nn.Linear(512, 10, bias=True)\n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)\n",
    "torch.nn.init.xavier_uniform_(linear4.weight)\n",
    "torch.nn.init.xavier_uniform_(linear5.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.209069237\n",
      "Epoch: 0002 cost = 0.087504402\n",
      "Epoch: 0003 cost = 0.062247038\n",
      "Epoch: 0004 cost = 0.050295848\n",
      "Epoch: 0005 cost = 0.041956827\n",
      "Epoch: 0006 cost = 0.033338562\n",
      "Epoch: 0007 cost = 0.029913915\n",
      "Epoch: 0008 cost = 0.025480697\n",
      "Epoch: 0009 cost = 0.023643117\n",
      "Epoch: 0010 cost = 0.021809930\n",
      "Epoch: 0011 cost = 0.019750046\n",
      "Epoch: 0012 cost = 0.020538975\n",
      "Epoch: 0013 cost = 0.016350599\n",
      "Epoch: 0014 cost = 0.015930574\n",
      "Epoch: 0015 cost = 0.012464210\n",
      "Epoch: 0016 cost = 0.016491905\n",
      "Epoch: 0017 cost = 0.015366506\n",
      "Epoch: 0018 cost = 0.010395721\n",
      "Epoch: 0019 cost = 0.013211161\n",
      "Epoch: 0020 cost = 0.012775788\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    for X,Y in data_loader:\n",
    "        X = X.view(-1, 28*28).to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost/total_batch\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9772999882698059\n",
      "Label:  1\n",
      "Prediction:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\la\\Anaconda3\\envs\\tf20\\lib\\site-packages\\torchvision\\datasets\\mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\la\\Anaconda3\\envs\\tf20\\lib\\site-packages\\torchvision\\datasets\\mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf20",
   "language": "python",
   "name": "tf20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
