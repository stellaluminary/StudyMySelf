{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Models of Computation, document distance Code\n",
    "\n",
    "URL : https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-006-introduction-to-algorithms-fall-2011/lecture-notes/<br>\n",
    "data : https://courses.csail.mit.edu/6.006/fall11/notes.shtml<br>\n",
    "URL : https://courses.csail.mit.edu/6.006/fall11/notes.shtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "math.arcos(x), math.sqrt(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# docdist1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operation 1 : read a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    try:\n",
    "        f = open(filename,'r',encoding='UTF8')\n",
    "        return f.readlines()\n",
    "    except IOError:\n",
    "        print(\"Error opening or reading input file\", filename)\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Project Gutenberg's In the Year 2889, by Jules Verne and Michel Verne\\n\", '\\n', 'This eBook is for the use of anyone anywhere at no cost and with\\n', 'almost no restrictions whatsoever.  You may copy it, give it away or\\n', 're-use it under the terms of the Project Gutenberg License included\\n', 'with this eBook or online at www.gutenberg.org\\n', '\\n', '\\n', 'Title: In the Year 2889\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "f1 = open(\"t1.verne.txt\",'r', encoding='UTF8')\n",
    "line1 = f1.readlines()\n",
    "print(line1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1057, list)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line1), type(line1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Project Gutenberg eBook, The Bobbsey Twins on Blueberry Island, by\\n', 'Laura Lee Hope\\n', '\\n', '\\n', 'This eBook is for the use of anyone anywhere at no cost and with\\n', 'almost no restrictions whatsoever.  You may copy it, give it away or\\n', 're-use it under the terms of the Project Gutenberg License included\\n', 'with this eBook or online at www.gutenberg.org\\n', '\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "f2 = open(\"t2.bobsey.txt\",'r', encoding='UTF8')\n",
    "line2 = f2.readlines()\n",
    "print(line2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6667, list)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line2), type(line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operation 2: split the text lines into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_string(line):\n",
    "    word_list = []\n",
    "    character_list = []\n",
    "    #print(line)\n",
    "    for c in line:\n",
    "        if c.isalnum():\n",
    "            character_list.append(c)\n",
    "        elif len(character_list) > 0:\n",
    "            word = \"\".join(character_list)\n",
    "            #print(word)\n",
    "            word = word.lower()\n",
    "            word_list.append(word)\n",
    "            #print('word_list',word_list)\n",
    "            character_list = []\n",
    "    if len(character_list)>0:\n",
    "        word = \"\".join(character_list)\n",
    "        word = word.lower()\n",
    "        word_list.append(word)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#str.isalnum() 숫자와 알파벳만으로 존재하는지 맞으면 True 아니면 False\n",
    "#비슷한 예로 isdigit()\n",
    "str1 = \"thisthisthistthis2000\"\n",
    "print(str1.isalnum())\n",
    "str2 = \"this is string example....wow!!!###\"\n",
    "print(str2.isalnum())\n",
    "str3 = \"this is\"\n",
    "print(str3.isalnum())\n",
    "#띄어쓰기 또한 False로 간주"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n",
      "t\n",
      "r\n",
      ":\n",
      " \n",
      "l\n",
      "i\n",
      "n\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "for a in \"str: line\":\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project',\n",
       " 'gutenberg',\n",
       " 's',\n",
       " 'in',\n",
       " 'the',\n",
       " 'year',\n",
       " '2889',\n",
       " 'by',\n",
       " 'jules',\n",
       " 'verne',\n",
       " 'and',\n",
       " 'michel',\n",
       " 'verne']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words_from_string(line1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_line_list(L):\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        word_list = word_list + words_in_line\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project',\n",
       " 'gutenberg',\n",
       " 's',\n",
       " 'in',\n",
       " 'the',\n",
       " 'year',\n",
       " '2889',\n",
       " 'by',\n",
       " 'jules',\n",
       " 'verne']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words_from_line_list(line1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [4,5]\n",
    "a = a+b\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operation 3: Count Frequency of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frequency(word_list):\n",
    "    L = []\n",
    "    for new_word in word_list:\n",
    "        for entry in L:\n",
    "            if new_word == entry[0]:\n",
    "                entry[1] = entry[1] + 1\n",
    "                break\n",
    "        else:\n",
    "            L.append([new_word,1])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['project', 88],\n",
       " ['gutenberg', 93],\n",
       " ['s', 41],\n",
       " ['in', 159],\n",
       " ['the', 598],\n",
       " ['year', 14],\n",
       " ['2889', 11],\n",
       " ['by', 53],\n",
       " ['jules', 6],\n",
       " ['verne', 10]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_frequency(get_words_from_line_list(line1))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['project', 88],\n",
       " ['gutenberg', 93],\n",
       " ['s', 41],\n",
       " ['in', 159],\n",
       " ['the', 598],\n",
       " ['year', 14],\n",
       " ['2889', 11],\n",
       " ['by', 53],\n",
       " ['jules', 6],\n",
       " ['verne', 10]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = count_frequency(get_words_from_line_list(line1))\n",
    "cnt[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operation 4: sort words into alphabetic order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertion_sort(A):\n",
    "    #print('print A',A)\n",
    "    for j in range(len(A)):\n",
    "        key = A[j]\n",
    "        i = j-1\n",
    "        #print(key, i, j)\n",
    "        while i>-1 and A[i]>key:\n",
    "            A[i+1] = A[i]\n",
    "            i = i-1\n",
    "        A[i+1] = key\n",
    "        #print('print A',A)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['000', 10], ['1', 46], ['10', 2], ['100', 1], ['1000', 2]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insertion_sort(cnt)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['000', 10],\n",
       " ['1', 46],\n",
       " ['10', 2],\n",
       " ['100', 1],\n",
       " ['1000', 2],\n",
       " ['11', 1],\n",
       " ['1100', 1],\n",
       " ['12', 1],\n",
       " ['1311', 1],\n",
       " ['150', 1]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insertion_sort(cnt[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(['ddz'] > ['zzo'])\n",
    "print([8] > [5])\n",
    "print(['8'] > ['5'])\n",
    "print(['ㄴ'] < ['ㅅ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies_for_file(filename):\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    insertion_sort(freq_mapping)\n",
    "    \n",
    "    print (\"File\",filename)\n",
    "    print (len(line_list),\"lines,\")\n",
    "    print (len(word_list),\"words,\")\n",
    "    print (len(freq_mapping),\"distinct words\")\n",
    "\n",
    "    return freq_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File t1.verne.txt\n",
      "1057 lines,\n",
      "8943 words,\n",
      "2150 distinct words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['000', 10],\n",
       " ['1', 46],\n",
       " ['10', 2],\n",
       " ['100', 1],\n",
       " ['1000', 2],\n",
       " ['11', 1],\n",
       " ['1100', 1],\n",
       " ['12', 1],\n",
       " ['1311', 1],\n",
       " ['150', 1]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies_for_file(\"t1.verne.txt\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File t2.bobsey.txt\n",
      "6667 lines,\n",
      "49785 words,\n",
      "3354 distinct words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['0', 3],\n",
       " ['000', 1],\n",
       " ['1', 49],\n",
       " ['103', 1],\n",
       " ['112', 1],\n",
       " ['123', 1],\n",
       " ['126', 1],\n",
       " ['128', 1],\n",
       " ['13', 1],\n",
       " ['136', 1]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies_for_file(\"t2.bobsey.txt\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product(L1,L2):\n",
    "    sum = 0.\n",
    "    for word1, count1 in L1:\n",
    "        for word2, count2 in L2:\n",
    "            if word1 == word2:\n",
    "                sum += count1 * count2\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_angle(L1,L2):\n",
    "    numerator = inner_product(L1,L2) #numerator 분자\n",
    "    denominator = math.sqrt(inner_product(L1,L1) * inner_product(L2,L2)) #denominator 분모\n",
    "    return math.acos(numerator/denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show():\n",
    "    import time\n",
    "    start = time.time()\n",
    "    sorted_word_list_1 = word_frequencies_for_file('t1.verne.txt')\n",
    "    sorted_word_list_2 = word_frequencies_for_file('t2.bobsey.txt')\n",
    "    distance = vector_angle(sorted_word_list_1,sorted_word_list_2)\n",
    "    print (\"The distance between the documents is: %0.6f (radians)\"%distance)\n",
    "    end = time.time()\n",
    "    print(end-start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File t1.verne.txt\n",
      "1057 lines,\n",
      "8943 words,\n",
      "2150 distinct words\n",
      "File t2.bobsey.txt\n",
      "6667 lines,\n",
      "49785 words,\n",
      "3354 distinct words\n",
      "The distance between the documents is: 0.582949 (radians)\n",
      "3.621087074279785 s\n"
     ]
    }
   ],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# docdist2.py\n",
    "\n",
    "docdist2.py - changed concatenate to extend in get_words_from_line_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_line_list(L):\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        # Using \"extend\" is much more efficient than concatenation here:\n",
    "        # docdist1.py에서는 word_list = word_list + words_in_line\n",
    "        word_list.extend(words_in_line)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 6, 7, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "a = [1,5,6,7]\n",
    "b = [5,6,7,8]\n",
    "a.extend(b) #O(len(b))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 7, 8, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "a=[5,6,7,8]\n",
    "a[len(a):]=[8,9,10]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File t1.verne.txt\n",
      "1057 lines,\n",
      "8943 words,\n",
      "2150 distinct words\n",
      "File t2.bobsey.txt\n",
      "6667 lines,\n",
      "49785 words,\n",
      "3354 distinct words\n",
      "The distance between the documents is: 0.582949 (radians)\n",
      "2.971553325653076 s\n"
     ]
    }
   ],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# docdist3.py\n",
    "\n",
    "docdist3.py - improved dot product to exploit sorted order and achieve linear instead of quadratic time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product(L1,L2):\n",
    "    \"\"\"\n",
    "    Inner product between two vectors, where vectors\n",
    "    are represented as alphabetically sorted (word,freq) pairs.\n",
    "\n",
    "    Example: inner_product([[\"and\",3],[\"of\",2],[\"the\",5]],\n",
    "                           [[\"and\",4],[\"in\",1],[\"of\",1],[\"this\",2]]) = 14.0 \n",
    "    \"\"\"\n",
    "    sum = 0.0\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i<len(L1) and j<len(L2):\n",
    "        # L1[i:] and L2[j:] yet to be processed\n",
    "        if L1[i][0] == L2[j][0]:\n",
    "            # both vectors have this word\n",
    "            sum += L1[i][1] * L2[j][1]\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif L1[i][0] < L2[j][0]:\n",
    "            # word L1[i][0] is in L1 but not L2\n",
    "            i += 1\n",
    "        else:\n",
    "            # word L2[j][0] is in L2 but not L1\n",
    "            j += 1\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File t1.verne.txt\n",
      "1057 lines,\n",
      "8943 words,\n",
      "2150 distinct words\n",
      "File t2.bobsey.txt\n",
      "6667 lines,\n",
      "49785 words,\n",
      "3354 distinct words\n",
      "The distance between the documents is: 0.582949 (radians)\n",
      "1.80826735496521 s\n"
     ]
    }
   ],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# docdist4.py\n",
    "docdist4.py - changed count_frequency to use dictionaries instead of lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def count_frequency(word_list):\n",
    "    L = []\n",
    "    for new_word in word_list:\n",
    "        for entry in L:\n",
    "            if new_word == entry[0]:\n",
    "                entry[1] = entry[1] + 1\n",
    "                break\n",
    "        else:\n",
    "            L.append([new_word,1])\n",
    "    return L\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frequency(word_list):\n",
    "    \"\"\"\n",
    "    Return a list giving pairs of form: (word,frequency)\n",
    "    \"\"\"\n",
    "    D = {}\n",
    "    for new_word in word_list:\n",
    "        if new_word in D:\n",
    "            D[new_word] = D[new_word]+1\n",
    "        else:\n",
    "            D[new_word] = 1\n",
    "    return list(D.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('project', 88),\n",
       " ('gutenberg', 93),\n",
       " ('s', 41),\n",
       " ('in', 159),\n",
       " ('the', 598),\n",
       " ('year', 14),\n",
       " ('2889', 11),\n",
       " ('by', 53),\n",
       " ('jules', 6),\n",
       " ('verne', 10)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_frequency(get_words_from_line_list(line1))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "dict_values([1, 2, 3, 4])\n",
      "dict_items([('z', 1), ('f', 2), ('c', 3), ('d', 4)])\n",
      "dict_keys(['z', 'f', 'c', 'd'])\n"
     ]
    }
   ],
   "source": [
    "a={'z':1,'f':2,'c':3,'d':4}\n",
    "print(a['c'])\n",
    "print(a.values())\n",
    "print(a.items())\n",
    "print(a.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File t1.verne.txt\n",
      "1057 lines,\n",
      "8943 words,\n",
      "2150 distinct words\n",
      "File t2.bobsey.txt\n",
      "6667 lines,\n",
      "49785 words,\n",
      "3354 distinct words\n",
      "The distance between the documents is: 0.582949 (radians)\n",
      "0.7751026153564453 s\n"
     ]
    }
   ],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def word_frequencies_for_file(filename):\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    insertion_sort(freq_mapping)\n",
    "    \n",
    "    print (\"File\",filename)\n",
    "    print (len(line_list),\"lines,\")\n",
    "    print (len(word_list),\"words,\")\n",
    "    print (len(freq_mapping),\"distinct words\")\n",
    "\n",
    "    return freq_mapping\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    insertion_sort(freq_mapping)\n",
    "    return freq_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('z', 1), ('f', 2), ('c', 3), ('d', 4)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('z', 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_words_from_line_list(line1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = count_frequency(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('000', 10),\n",
       " ('1', 46),\n",
       " ('10', 2),\n",
       " ('100', 1),\n",
       " ('1000', 2),\n",
       " ('11', 1),\n",
       " ('1100', 1),\n",
       " ('12', 1),\n",
       " ('1311', 1),\n",
       " ('150', 1)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insertion_sort(b)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def insertion_sort(A):\n",
    "    for j in range(len(A)):\n",
    "        key = A[j]\n",
    "        i = j-1\n",
    "        while i>-1 and A[i]>key:\n",
    "            A[i+1] = A[i]\n",
    "            i = i-1\n",
    "        A[i+1] = key\n",
    "    return A\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between the documents is: 0.582949 (radians)\n",
      "0.7598824501037598 s\n"
     ]
    }
   ],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# docdist5.py\n",
    "docdist5.py - change get_words_from_string to use string translate and split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def get_words_from_string(line):\n",
    "    word_list = []\n",
    "    character_list = []\n",
    "    #print(line)\n",
    "    for c in line:\n",
    "        if c.isalnum():\n",
    "            character_list.append(c)\n",
    "        elif len(character_list) > 0:\n",
    "            word = \"\".join(character_list)\n",
    "            #print(word)\n",
    "            word = word.lower()\n",
    "            word_list.append(word)\n",
    "            #print('word_list',word_list)\n",
    "            character_list = []\n",
    "    if len(character_list)>0:\n",
    "        word = \"\".join(character_list)\n",
    "        word = word.lower()\n",
    "        word_list.append(word)\n",
    "    return word_list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "#translation_table = string.maketrans(string.punctuation+string.uppercase, \" \"*len(string.punctuation)+string.lowercase)\n",
    "#python 3 table=str.maketrans(A,B) #A to B\n",
    "#str.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_string(line):\n",
    "    \"\"\"\n",
    "    Return a list of the words in the given input string,\n",
    "    converting each word to lower-case.\n",
    "\n",
    "    Input:  line (a string)\n",
    "    Output: a list of strings \n",
    "              (each string is a sequence of alphanumeric characters)\n",
    "    \"\"\"\n",
    "    import string\n",
    "    translation_table = line.maketrans(string.punctuation+string.ascii_uppercase,\" \"*len(string.punctuation)+string.ascii_lowercase)\n",
    "    line = line.translate(translation_table)\n",
    "    word_list = line.split()\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between the documents is: 0.582949 (radians)\n",
      "0.7635235786437988 s\n"
     ]
    }
   ],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Project Gutenberg's In the Year 2889, by Jules Verne and Michel Verne\\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdcdcdcd\n"
     ]
    }
   ],
   "source": [
    "word = 'ababcdcd'\n",
    "table = word.maketrans('ab','cd')\n",
    "print(word.translate(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{97: 99, 98: 100}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.maketrans('abab','cdcd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cdcdcdcd'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.translate(word.maketrans('abab','cdcd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.ascii_uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.ascii_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project gutenberg s in the year 2889  by jules verne and michel verne\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = line1[0].maketrans(string.punctuation+string.ascii_uppercase,\" \"*len(string.punctuation)+string.ascii_lowercase)\n",
    "sett = line1[0].translate(table)\n",
    "print(sett)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# docdist6.py\n",
    "\n",
    "docdist6.py - changed sorting from insertion sort to merge sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertion_sort(A):\n",
    "    \"\"\"\n",
    "    Sort list A into order, in place.\n",
    "\n",
    "    From Cormen/Leiserson/Rivest/Stein,\n",
    "    Introduction to Algorithms (second edition), page 17,\n",
    "    modified to adjust for fact that Python arrays use \n",
    "    0-indexing.\n",
    "    \"\"\"\n",
    "    for j in range(len(A)):\n",
    "        key = A[j]\n",
    "        # insert A[j] into sorted sequence A[0..j-1]\n",
    "        i = j-1\n",
    "        while i>-1 and A[i]>key:\n",
    "            A[i+1] = A[i]\n",
    "            i = i-1\n",
    "        A[i+1] = key\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sort(A):\n",
    "    \"\"\"\n",
    "    Sort list A into order, and return result.\n",
    "    \"\"\"\n",
    "    n = len(A)\n",
    "    if n==1: \n",
    "        return A\n",
    "    mid = n//2     # floor division\n",
    "    L = merge_sort(A[:mid])\n",
    "    R = merge_sort(A[mid:])\n",
    "    return merge(L,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(L,R):\n",
    "    \"\"\"\n",
    "    Given two sorted sequences L and R, return their merge.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    j = 0\n",
    "    answer = []\n",
    "    while i<len(L) and j<len(R):\n",
    "        if L[i]<R[j]:\n",
    "            answer.append(L[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            answer.append(R[j])\n",
    "            j += 1\n",
    "    if i<len(L):\n",
    "        answer.extend(L[i:])\n",
    "    if j<len(R):\n",
    "        answer.extend(R[j:])\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    freq_mapping = merge_sort(freq_mapping)\n",
    "    return freq_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between the documents is: 0.582949 (radians)\n",
      "0.07083868980407715 s\n"
     ]
    }
   ],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# docdict7.py\n",
    "docdist7.py - remove sorting altogether via more hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frequency(word_list):\n",
    "    \"\"\"\n",
    "    Return a list giving pairs of form: (word,frequency)\n",
    "    \"\"\"\n",
    "    D = {}\n",
    "    for new_word in word_list:\n",
    "        if new_word in D:\n",
    "            D[new_word] = D[new_word]+1\n",
    "        else:\n",
    "            D[new_word] = 1\n",
    "    return list(D.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return dictionary of (word,frequency) pairs for the given file.\n",
    "    \"\"\"\n",
    "\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    return freq_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product(D1,D2):\n",
    "    \"\"\"\n",
    "    Inner product between two vectors, where vectors\n",
    "    are represented as dictionaries of (word,freq) pairs.\n",
    "\n",
    "    Example: inner_product({\"and\":3,\"of\":2,\"the\":5},\n",
    "                           {\"and\":4,\"in\":1,\"of\":1,\"this\":2}) = 14.0 \n",
    "    \"\"\"\n",
    "    D1=dict(D1)\n",
    "    D2=dict(D2)\n",
    "    sum = 0.0\n",
    "    for key in D1:\n",
    "        if key in D2:\n",
    "            sum += D1[key] * D2[key]\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between the documents is: 0.582949 (radians)\n",
      "0.04587578773498535 s\n"
     ]
    }
   ],
   "source": [
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# docdict8.py\n",
    "docdist8.py - treat whole file as a single \"line\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def read_file(filename):\n",
    "    try:\n",
    "        f = open(filename,'r',encoding='UTF8')\n",
    "        return f.readlines()\n",
    "    except IOError:\n",
    "        print(\"Error opening or reading input file\", filename)\n",
    "        sys.exit()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    \"\"\" \n",
    "    Read the text file with the given filename;\n",
    "    return a list of the lines of text in the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        f = open(filename, 'r', encoding='UTF8')\n",
    "        return f.read()\n",
    "    except IOError:\n",
    "        print (\"Error opening or reading input file: \",filename)\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def get_words_from_string(line):\n",
    "    \"\"\"\n",
    "    Return a list of the words in the given input string,\n",
    "    converting each word to lower-case.\n",
    "\n",
    "    Input:  line (a string)\n",
    "    Output: a list of strings \n",
    "              (each string is a sequence of alphanumeric characters)\n",
    "    \"\"\"\n",
    "    translation_table = line.maketrans(string.punctuation+string.ascii_uppercase,\" \"*len(string.punctuation)+string.ascii_lowercase)\n",
    "    line = line.translate(translation_table)\n",
    "    word_list = line.split()\n",
    "    return word_list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_text(text):\n",
    "    \"\"\"\n",
    "    Parse the given text into words.\n",
    "    Return list of all words found.\n",
    "    \"\"\"\n",
    "    translation_table = text.maketrans(string.punctuation+string.ascii_uppercase,\" \"*len(string.punctuation)+string.ascii_lowercase)\n",
    "    text = text.translate(translation_table)\n",
    "    word_list = text.split()\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return dictionary of (word,frequency) pairs for the given file.\n",
    "    \"\"\"\n",
    "    text = read_file(filename)\n",
    "    word_list = get_words_from_text(text)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    return freq_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between the documents is: 0.582949 (radians)\n",
      "0.01795339584350586 s\n"
     ]
    }
   ],
   "source": [
    "show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf20",
   "language": "python",
   "name": "tf20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
