{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification\n",
    "http://cs231n.github.io/classification/<br>\n",
    "   - Intro to Image Classification, data-driven approach, pipeline\n",
    "   - Nearest Neighbor Classifier\n",
    "       - K-Nearest Neighbor\n",
    "   - Validation sets, Cross-Validation, hyperparameter tuning\n",
    "   - Pros/Cons of Nearest Neighbor\n",
    "   - Summary\n",
    "   - Summary : Applying KNN in practice\n",
    "   - Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Image Classification</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">KNN</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR - 10 dataset : http://www.cs.toronto.edu/~kriz/cifar.html <br>\n",
    "60000 data, 32x32x3 color images in 10 classes with 6,000 images per class <br>\n",
    "50000 training images and 10000 test images\n",
    "\n",
    "about how to bring cifar 10 data <br>\n",
    "https://github.com/MahanFathi/CS231/blob/master/assignment1/knn.ipynb<br>\n",
    "https://github.com/cthorey/CS231/blob/master/assignment3/cs231n/data_utils.py<br>\n",
    "https://mattpetersen.github.io/load-cifar10-with-numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
      "b'training batch 1 of 5'\n",
      "[6, 9, 9, 4, 1]\n",
      "10000\n",
      "(10000, 3072)\n",
      "[b'leptodactylus_pentadactylus_s_000004.png', b'camion_s_000148.png', b'tipper_truck_s_001250.png']\n",
      "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
      "b'training batch 2 of 5'\n",
      "[1, 6, 6, 8, 8]\n",
      "10000\n",
      "(10000, 3072)\n",
      "[b'auto_s_000241.png', b'bufo_viridis_s_001109.png', b'rana_catesbeiana_s_000111.png']\n",
      "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
      "b'training batch 3 of 5'\n",
      "[8, 5, 0, 6, 9]\n",
      "10000\n",
      "(10000, 3072)\n",
      "[b'pleasure_boat_s_000152.png', b'maltese_s_000987.png', b'dive_bomber_s_000875.png']\n",
      "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
      "b'training batch 4 of 5'\n",
      "[0, 6, 0, 2, 7]\n",
      "10000\n",
      "(10000, 3072)\n",
      "[b'plane_s_000772.png', b'bufo_bufo_s_001873.png', b'stealth_bomber_s_000779.png']\n",
      "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
      "b'training batch 5 of 5'\n",
      "[1, 8, 5, 1, 5]\n",
      "10000\n",
      "(10000, 3072)\n",
      "[b'compact_car_s_001706.png', b'icebreaker_s_001689.png', b'peke_s_000545.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dictstack={}\n",
    "\n",
    "for i in range(5):\n",
    "    file_path = os.path.join('.\\\\cifar-10-batches-py','data_batch_'+str(i+1))\n",
    "    dictfile = unpickle(file_path)  \n",
    "    print(dictfile.keys())\n",
    "    print(dictfile[b'batch_label'])\n",
    "    print(dictfile[b'labels'][:5])\n",
    "    print(len(dictfile[b'labels']))\n",
    "    print(dictfile[b'data'].shape)\n",
    "    print(dictfile[b'filenames'][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/cthorey/CS231/blob/master/assignment3/cs231n/data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_CIFAR_batch(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = pickle.load(f, encoding='latin1')\n",
    "        X=datadict['data']\n",
    "        Y=datadict['labels']\n",
    "        #print(X.shape) # (10000, 3072)\n",
    "        X=X.reshape(10000,3,32,32).transpose(0,2,3,1).astype('float')\n",
    "        Y=np.array(Y)\n",
    "        #print(X.shape, Y.shape) # (10000, 32, 32, 3) (10000,)\n",
    "        return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR10(ROOT):\n",
    "    xs=[]\n",
    "    ys=[]\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(ROOT, 'data_batch_%d' % (b))\n",
    "        #print(b)\n",
    "        X,Y=load_CIFAR_batch(f)        \n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "        Xtr = np.concatenate(xs)\n",
    "        Ytr = np.concatenate(ys)\n",
    "        #print('In load_CIFAR:',Xtr.shape, Ytr.shape)\n",
    "    del X,Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_CIFAR10('./cifar-10-batches-py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000,) (10000, 32, 32, 3) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59., 62., 63.],\n",
       "       [43., 46., 45.],\n",
       "       [50., 48., 43.],\n",
       "       [68., 54., 42.],\n",
       "       [98., 73., 52.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,0,:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 label : ['ariplane', 'automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 distance \n",
    "I_1, I_2 are two images and representing them as vectors\n",
    "$$d_1(l_1,I_2) = \\sum_{p} \\left\\vert(I_1^p - I_2^p) \\right\\vert$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Ytr, Xte, Yte = load_CIFAR10('./cifar-10-batches-py') # a magic function we provide\n",
    "# flatten out all images to be one-dimensional\n",
    "Xtr_rows = Xtr.reshape(Xtr.shape[0], 32 * 32 * 3) # Xtr_rows becomes 50000 x 3072\n",
    "Xte_rows = Xte.reshape(Xte.shape[0], 32 * 32 * 3) # Xte_rows becomes 10000 x 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NearestNeighbor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\" X is N x D where each row is an example. Y is 1-dimension of size N \"\"\"\n",
    "        # the nearest neighbor classifier simply remembers all the training data\n",
    "        self.Xtr = X\n",
    "        self.ytr = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" X is N x D where each row is an example we wish to predict label for \"\"\"\n",
    "        num_test = X.shape[0]\n",
    "        # lets make sure that the output type matches the input type\n",
    "        Ypred = np.zeros(num_test, dtype = self.ytr.dtype)\n",
    "        print(num_test)\n",
    "        # loop over all test rows\n",
    "        for i in range(num_test):\n",
    "            # find the nearest training image to the i'th test image\n",
    "            # using the L1 distance (sum of absolute value differences)\n",
    "            distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)\n",
    "            min_index = np.argmin(distances) # get the index with smallest distance\n",
    "            Ypred[i] = self.ytr[min_index] # predict the label of the nearest example\n",
    "            #print(distances, min_index, Ypred)\n",
    "\n",
    "        return Ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6df666ae39a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNearestNeighbor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXte_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mYte_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXte_rows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy: %f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYte_predict\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mYte\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-f23d740b62f1>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m# find the nearest training image to the i'th test image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m# using the L1 distance (sum of absolute value differences)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXtr\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mmin_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# get the index with smallest distance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mYpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mytr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmin_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# predict the label of the nearest example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn=NearestNeighbor()\n",
    "nn.train(Xte_rows, Ytr)\n",
    "Yte_predict = nn.predict(Xte_rows)\n",
    "\n",
    "print('accuracy: %f' % (np.mean(Yte_predict == Yte)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 distance \n",
    "$$d_2(l_1,I_2) = \\sqrt{\\sum_{p} (I_1^p - I_2^p)^2 }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert below distance code inside def predict in class NearestNeighbor  \n",
    "#distances = np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
