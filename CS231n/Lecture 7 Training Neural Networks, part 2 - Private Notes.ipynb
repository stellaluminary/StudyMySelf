{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 7 Training Neural Networks, part 2 - Private Notes\n",
    "slide : http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture7.pdf <br>\n",
    "video : https://www.youtube.com/watch?v=_JB0AO7QxSA&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv<br>\n",
    " - Fancier Optimizer\n",
    " - Regularization\n",
    " - Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nitty-gritty : (쟁점 상황의) 핵심<br>\n",
    "allude : 암시하다, 시사(示唆)하다, 넌지시 말하다<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/7-16.png'>\n",
    "<font size=4 color='blue'>Jitter : to move or shake slightly in an uncontrolled way </font>\n",
    "<img src='./Lesson pic/7-18.png'>\n",
    "<br>\n",
    "<font size=4 color='red'> Saddle points much more common in high dimension</font>\n",
    "<img src='./Lesson pic/7-20.png'>\n",
    "<img src='./Lesson pic/7-21.png'>\n",
    "<img src='./Lesson pic/7-22.png'>\n",
    "<img src='./Lesson pic/7-24.png'>\n",
    "<img src='./Lesson pic/7-27.png'>\n",
    "<img src='./Lesson pic/7-28.png'>\n",
    "<img src='./Lesson pic/7-29.png'><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'><b> Q : What happens to the step size over long time?</b></font>\n",
    "<img src='./Lesson pic/7-31.png'>\n",
    "<img src='./Lesson pic/7-32.png'>\n",
    "<img src='./Lesson pic/7-33.png'>\n",
    "<img src='./Lesson pic/7-35.png'>\n",
    "<img src='./Lesson pic/7-37.png'>\n",
    "<img src='./Lesson pic/7-38.png'><br>\n",
    "<font size=5 color='blue'><b>Q : Which one of these learning rates is best to use?</b></font>\n",
    "<img src='./Lesson pic/7-40.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/7-42.png'>\n",
    "<img src='./Lesson pic/7-44.png'>\n",
    "<img src='./Lesson pic/7-45.png'>\n",
    "<img src='./Lesson pic/7-47.png'>\n",
    "<img src='./Lesson pic/7-48.png'>\n",
    "<img src='./Lesson pic/7-49.png'>\n",
    "<img src='./Lesson pic/7-51.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In practice:\n",
    " - Adam is a good default choice in most cases\n",
    " - If you can afford to do full batch updates then try out L-BFGS(don't forget to disable all sources of noise)\n",
    "<img src='./Lesson pic/7-53.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ensembles\n",
    " 1. Train multiple independent models\n",
    " - At test time average their results\n",
    " \n",
    "<font size=5 color='blue'>Enjoy 2% extra performance</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/7-56.png'>\n",
    "<img src='./Lesson pic/7-57.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to improve single - model performance?\n",
    "<font size=5 color='red'><b>Regularization</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/7-59.png'>\n",
    "<img src='./Lesson pic/7-60.png'>\n",
    "<img src='./Lesson pic/7-61.png'>\n",
    "<img src='./Lesson pic/7-62.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'><b>Another Interpretation:</b></font><br><br>\n",
    "<font size=5 color='blue'><b>=>Dropout is training a large ensemble of models(that share parameters).</b></font><br>\n",
    "<font size=5 color='blue'><b>Each binary mask is one model</b></font><br>\n",
    "<font size=5 color='blue'><b>An FC layer with 4096 units has $2^{4096} ~ 10^{1233}$ possible masks!</b></font><br>\n",
    "<font size=5 color='blue'><b>Only ~ $10^{82}$ atoms in the universe.. </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/7-64.png'>\n",
    "<img src='./Lesson pic/7-68.png'>\n",
    "<img src='./Lesson pic/7-69.png'>\n",
    "<img src='./Lesson pic/7-70.png'>\n",
    "<img src='./Lesson pic/7-71.png'>\n",
    "<img src='./Lesson pic/7-73.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/7-75.png'><br>\n",
    "<font size=5 color='blue'><b>Data Augmentation : Horizontal Flips</b></font><br>\n",
    "<img src='./Lesson pic/7-78.png'>\n",
    "<img src='./Lesson pic/7-80.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "<font size=5>Get creative for your problem</font><br>\n",
    "\n",
    "Random mix/combinations of:\n",
    " - translation\n",
    " - rotation\n",
    " - stretching\n",
    " - shearing\n",
    " - lens distortions, ... (go crazy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/7-83,4.png'>\n",
    "<img src='./Lesson pic/7-85.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/7-87.png'>\n",
    "<img src='./Lesson pic/7-90.png'>\n",
    "<img src='./Lesson pic/7-93.png'>\n",
    "<img src='./Lesson pic/7-96.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaway for your projects and beyond:\n",
    "<font size=5>Have some dataset of interest but it has \\< ~1M images? </font><br>\n",
    " 1. Find a very large dataset that has similar data, train a big ConvNet there\n",
    " 2. Transfer learn to your dataset<br><br>\n",
    "Deep learning frameworks provide a “Model Zoo” of pretrained models so you don’t need to train your own<br>\n",
    "Caffe: https://github.com/BVLC/caffe/wiki/Model-Zoo<br>\n",
    "TensorFlow: https://github.com/tensorflow/models<br>\n",
    "PyTorch: https://github.com/pytorch/vision<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    " - Optimization\n",
    "  - Momentum, RMSProp, Adam, etc\n",
    " - Regularization\n",
    "  - Dropout, etc\n",
    " - Transfer learning\n",
    "  - Use this for your projects!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
