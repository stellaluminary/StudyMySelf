{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks \n",
    "- RNN, LSTM, GRU \n",
    "- Language modeling \n",
    "- Image captioning, visual question answering \n",
    "- Soft attention \n",
    "\n",
    "slides : http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf\n",
    "videos : https://www.youtube.com/watch?v=6niqTuYFZLQ&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Vanilla Neural Networks - one to one</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/10-12.png'>\n",
    "<font color='blue'><b>e.g. Vanilla Neural Networks - one to one</b></font><br>\n",
    "<font color='blue'><b>e.g. Image Captioning:image -> sequence of words</b></font><br>\n",
    "<font color='blue'><b>e.g. Sentiment Classification : sequence of words -> sentiment</b></font><br>\n",
    "<font color='blue'><b>e.g. Machine Translation : seq of words -> seq of words</b></font><br>\n",
    "<font color='blue'><b>e.g. Video classification on frame level</b></font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Processing of Non-Sequence Data\n",
    "- Classify images by taking a series of “glimpses”\n",
    "<img src='./Lesson pic/10-17.png'>\n",
    "<img src='./Lesson pic/10-19.png'>\n",
    "<img src='./Lesson pic/10-20.png'>\n",
    "\n",
    "<font color='red'><b>Notice: the same function and the same set of parameters are used at every time step.</b></font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/10-22.png'>\n",
    "<img src='./Lesson pic/10-26.png'>\n",
    "<img src='./Lesson pic/10-29.png'>\n",
    "<img src='./Lesson pic/10-30.png'>\n",
    "<img src='./Lesson pic/10-31.png'>\n",
    "<img src='./Lesson pic/10-33.png'>\n",
    "\n",
    "<font size=5>$$h_t = tanh(W_{hh}h_{t-1} + W_{xh}x_t)$$</font>\n",
    "\n",
    "<img src='./Lesson pic/10-36.png'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/10-40.png'>\n",
    "<img src='./Lesson pic/10-41.png'>\n",
    "<img src='./Lesson pic/10-42.png'>\n",
    "<img src='./Lesson pic/10-43.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min-char-rnn.py gist: 112 lines of Python\n",
    "\n",
    "(https://gist.github.com/karpathy/d4dee566867f8291f086)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/10-46.png'>\n",
    "<img src='./Lesson pic/10-47.png'>\n",
    "<img src='./Lesson pic/10-48.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/10-53.png'>\n",
    "<img src='./Lesson pic/10-56.png'>\n",
    "<img src='./Lesson pic/10-57.png'>\n",
    "<img src='./Lesson pic/10-58.png'>\n",
    "<img src='./Lesson pic/10-59.png'>\n",
    "<img src='./Lesson pic/10-60.png'>\n",
    "<img src='./Lesson pic/10-61.png'>\n",
    "<img src='./Lesson pic/10-62.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/10-63.png'>\n",
    "<img src='./Lesson pic/10-64.png'>\n",
    "<img src='./Lesson pic/10-67.png'>\n",
    "<img src='./Lesson pic/10-69.png'>\n",
    "<img src='./Lesson pic/10-70.png'>\n",
    "<img src='./Lesson pic/10-74.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/10-75.png'>\n",
    "<img src='./Lesson pic/10-76.png'>\n",
    "<img src='./Lesson pic/10-77.png'>\n",
    "<img src='./Lesson pic/10-80.png'>\n",
    "<img src='./Lesson pic/10-84.png'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/10-85.png'>\n",
    "<img src='./Lesson pic/10-86.png'>\n",
    "<img src='./Lesson pic/10-87.png'>\n",
    "<img src='./Lesson pic/10-88.png'>\n",
    "<img src='./Lesson pic/10-89.png'>\n",
    "<img src='./Lesson pic/10-91.png'>\n",
    "<img src='./Lesson pic/10-94.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4><b>Largest singular value < 1: Vanishing gradients -> Change RNN architecture</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Lesson pic/10-96.png'>\n",
    "<img src='./Lesson pic/10-97.png'>\n",
    "<img src='./Lesson pic/10-99.png'>\n",
    "<img src='./Lesson pic/10-102.png'>\n",
    "<img src='./Lesson pic/10-103.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "- RNNs allow a lot of flexibility in architecture design\n",
    "- Vanilla RNNs are simple but don’t work very well\n",
    "- Common to use LSTM or GRU: their additive interactions\n",
    "improve gradient flow\n",
    "- Backward flow of gradients in RNN can explode or vanish.\n",
    "Exploding is controlled with gradient clipping. Vanishing is\n",
    "controlled with additive interactions (LSTM)\n",
    "- Better/simpler architectures are a hot topic of current research\n",
    "- Better understanding (both theoretical and empirical) is needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
